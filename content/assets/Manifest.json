{
  "version": "1.0.0",
  "cliversion": "1.0.0",
  "changelog": "",
  "coreinstallurl": {
    "X64": "https://dellupdater.dell.com/non_du/ClientService/endpointmgmt/DellAIProStudio/Dell.AI.Framework.x64.zip",
    "ARM64": "https://dellupdater.dell.com/non_du/ClientService/endpointmgmt/DellAIProStudio/Dell.AI.Framework.arm64.zip"
  },
  "coreversion": {
    "dellcoreservices": "1.11.5.0",
    "dellaiframework": "1.0.3.0"
  },
  "coreguid": {
    "core": "48701f13-32b1-491b-af8a-6087af642cd1",
    "server": "9D34898C-B460-4001-BDE5-B6A68F2E82E4"
  },
  "models": [
    {
      "model": "Phi-3.5-mini-instruct",
      "license": "MIT license",
      "type": "LLM",
      "platform": "X64",
      "hardware": "NPU",
      "hardwareVendor": "Intel",
      "zipUrl": "https://dellupdater.dell.com/non_du/ClientService/endpointmgmt/DellAIProStudio/Dell.Model.Phi-3.5-mini-instruct.NPU.OVGAI.x64.zip",
      "zipName": "Dell.Model.Phi-3.5-mini-instruct.NPU.OVGAI.x64.zip",
      "description": "Phi-3.5-mini is a lightweight, state-of-the-art open model built upon datasets used for Phi-3 - synthetic data and filtered publicly available websites - with a focus on very high-quality, reasoning dense data. The model belongs to the Phi-3 model family and supports 128K token context length. The model underwent a rigorous enhancement process, incorporating both supervised fine-tuning, proximal policy optimization, and direct preference optimization to ensure precise instruction adherence and robust safety measures.",
      "recordSize": "1.62 GB",
      "modelSize": "3.8B params",
      "supportedLanguages": [ "Arabic", "Chinese", "Dutch", "English", "French", "German", "Italian", "Russian", "Spanish", "Ukrainian" ],
      "tagline": "Small, fast, instruction-tuned model with 128K context and strong reasoning.",
      "name": "phi3.5",
      "agentGuid": "791B9737-0611-40AB-9627-C6E18FDC10C9",
      "hfRepo": "https://huggingface.co/microsoft/Phi-3.5-mini-instruct"
    },
    {
      "model": "Phi-3.5-mini-instruct",
      "license": "MIT license",
      "type": "LLM",
      "platform": "ARM64",
      "hardware": "NPU",
      "hardwareVendor": "Qualcomm",
      "zipUrl": "https://dellupdater.dell.com/non_du/ClientService/endpointmgmt/DellAIProStudio/Dell.Model.Phi-3.5-mini-instruct.NPU.Genie.arm64.zip",
      "zipName": "Dell.Model.Phi-3.5-mini-instruct.NPU.Genie.arm64.zip",
      "description": "Phi-3.5-mini is a lightweight, state-of-the-art open model built upon datasets used for Phi-3 - synthetic data and filtered publicly available websites - with a focus on very high-quality, reasoning dense data. The model belongs to the Phi-3 model family and supports 128K token context length. The model underwent a rigorous enhancement process, incorporating both supervised fine-tuning, proximal policy optimization, and direct preference optimization to ensure precise instruction adherence and robust safety measures.",
      "recordSize": "1.96 GB",
      "modelSize": "3.8B params",
      "supportedLanguages": [ "Arabic", "Chinese", "Dutch", "English", "French", "German", "Italian", "Russian", "Spanish", "Ukrainian" ],
      "tagline": "Optimized for ARM64, fast reasoning and long context understanding.",
      "name": "phi3.5",
      "agentGuid": "791B9737-0611-40AB-9627-C6E18FDC10C9",
      "hfRepo": "https://huggingface.co/microsoft/Phi-3.5-mini-instruct"
    },
    {
      "model": "Phi-3.5-mini-instruct",
      "license": "MIT license",
      "type": "LLM",
      "platform": "X64",
      "hardware": "NPU",
      "hardwareVendor": "AMD",
      "zipUrl": "http://dellupdater.dell.com/non_du/ClientService/endpointmgmt/dpais/model/oga-vitis/Dell.Model.Phi-3.5-mini-instruct.NPU.OGA-Vitis.x64.zip",
      "zipName": "Dell.Model.Phi-3.5-mini-instruct.NPU.OGA-Vitis.x64.zip",
      "description": "Phi-3.5-mini is a lightweight, state-of-the-art open model built upon datasets used for Phi-3 - synthetic data and filtered publicly available websites - with a focus on very high-quality, reasoning dense data. The model belongs to the Phi-3 model family and supports 128K token context length. The model underwent a rigorous enhancement process, incorporating both supervised fine-tuning, proximal policy optimization, and direct preference optimization to ensure precise instruction adherence and robust safety measures.",
      "recordSize": "2.12 GB",
      "modelSize": "3.8B params",
      "supportedLanguages": [ "Arabic", "Chinese", "Dutch", "English", "French", "German", "Italian", "Russian", "Spanish", "Ukrainian" ],
      "tagline": "Small, fast, instruction-tuned model with 128K context and strong reasoning.",
      "name": "phi3.5",
      "agentGuid": "791B9737-0611-40AB-9627-C6E18FDC10C9",
      "hfRepo": "https://huggingface.co/microsoft/Phi-3.5-mini-instruct"
    },
    {
      "model": "Whisper-small.en",
      "license": "Apache 2.0",
      "type": "Transcription",
      "platform": "X64",
      "hardware": "NPU",
      "hardwareVendor": "Intel",
      "zipUrl": "https://dellupdater.dell.com/non_du/ClientService/endpointmgmt/DellAIProStudio/Dell.Model.Whisper-small.en.NPU.OVGAI.x64.zip",
      "zipName": "Dell.Model.Whisper-small.en.NPU.OVGAI.x64.zip",
      "description": "Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours of labelled data, Whisper models demonstrate a strong ability to generalise to many datasets and domains without the need for fine-tuning. Whisper is a Transformer based encoder-decoder model, also referred to as a sequence-to-sequence model.",
      "recordSize": "804.61 MB",
      "modelSize": "242M params",
      "supportedLanguages": [ "English" ],
      "tagline": "Robust English speech-to-text with wide domain generalization.",
      "name": "whisper",
      "agentGuid": "9B301E41-0AF7-48EA-8A16-0C6AF3AC8EB3",
      "hfRepo": "https://huggingface.co/openai/whisper-small.en"
    },
    {
      "model": "Whisper-small.en",
      "license": "Apache 2.0",
      "type": "Transcription",
      "platform": "ARM64",
      "hardware": "NPU",
      "hardwareVendor": "Qualcomm",
      "zipUrl": "https://dellupdater.dell.com/non_du/ClientService/endpointmgmt/DellAIProStudio/Dell.Model.Whisper-small.en.NPU.ORT-QNN.arm64.zip",
      "zipName": "Dell.Model.Whisper-small.en.NPU.ORT-QNN.arm64.zip",
      "description": "Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours of labelled data, Whisper models demonstrate a strong ability to generalise to many datasets and domains without the need for fine-tuning. Whisper is a Transformer based encoder-decoder model, also referred to as a sequence-to-sequence model.",
      "recordSize": "1.20 GB",
      "modelSize": "242M params",
      "supportedLanguages": [ "English" ],
      "tagline": "Accurate ASR model for English with strong out-of-the-box results.",
      "name": "whisper",
      "agentGuid": "9B301E41-0AF7-48EA-8A16-0C6AF3AC8EB3",
      "hfRepo": "https://huggingface.co/openai/whisper-small.en"
    },
    {
      "model": "Clip-vit-base-patch32",
      "license": "MIT license",
      "type": "Embedding",
      "platform": "X64",
      "hardware": "NPU",
      "hardwareVendor": "Intel",
      "zipUrl": "https://dellupdater.dell.com/non_du/ClientService/endpointmgmt/DellAIProStudio/Dell.Model.CLIP-vit-base-patch32.NPU.ORT-OV.x64.zip",
      "zipName": "Dell.Model.CLIP-vit-base-patch32.NPU.ORT-OV.x64.zip",
      "description": "The CLIP model was developed by researchers at OpenAI to learn about what contributes to robustness in computer vision tasks. The model was also developed to test the ability of models to generalize to arbitrary image classification tasks in a zero-shot manner. The model uses a ViT-B/32 Transformer architecture as an image encoder and uses a masked self-attention Transformer as a text encoder. These encoders are trained to maximize the similarity of (image, text) pairs via a contrastive loss.",
      "recordSize": "679.51 MB",
      "modelSize": "151M params",
      "supportedLanguages": [ "English" ],
      "tagline": "ViT-based model for zero-shot image-text similarity tasks.",
      "name": "openai-clip",
      "agentGuid": "E9AB3E38-BFE6-4AD3-8EC5-66905B1798D6",
      "hfRepo": "https://huggingface.co/openai/clip-vit-base-patch32"
    },
    {
      "model": "Clip-vit-base-patch32",
      "license": "MIT license",
      "type": "Embedding",
      "platform": "ARM64",
      "hardware": "NPU",
      "hardwareVendor": "Qualcomm",
      "zipUrl": "https://dellupdater.dell.com/non_du/ClientService/endpointmgmt/DellAIProStudio/Dell.Model.CLIP-vit-base-patch32.NPU.ORT-QNN.arm64.zip",
      "zipName": "Dell.Model.CLIP-vit-base-patch32.NPU.ORT-QNN.arm64.zip",
      "description": "The CLIP model was developed by researchers at OpenAI to learn about what contributes to robustness in computer vision tasks. The model was also developed to test the ability of models to generalize to arbitrary image classification tasks in a zero-shot manner. The model uses a ViT-B/32 Transformer architecture as an image encoder and uses a masked self-attention Transformer as a text encoder. These encoders are trained to maximize the similarity of (image, text) pairs via a contrastive loss.",
      "recordSize": "679.51 MB",
      "modelSize": "151M params",
      "supportedLanguages": [ "English" ],
      "tagline": "Cross-modal model trained for robust image-text pairing.",
      "name": "openai-clip",
      "agentGuid": "E9AB3E38-BFE6-4AD3-8EC5-66905B1798D6",
      "hfRepo": "https://huggingface.co/openai/clip-vit-base-patch32"
    },
    {
      "model": "Nomic-embed-text-v1.5",
      "license": "Apache 2.0",
      "type": "Embedding",
      "platform": "X64",
      "hardware": "CPU",
      "hardwareVendor": "Intel",
      "zipUrl": "https://dellupdater.dell.com/non_du/ClientService/endpointmgmt/DellAIProStudio/Dell.Model.Nomic-embed-text-v1.5.CPU.ORT.x64.zip",
      "zipName": "Dell.Model.Nomic-embed-text-v1.5.CPU.ORT.x64.zip",
      "description": "Nomic‑embed‑text is a high-performing, open-source text embedding model. It supports a maximum context window of 8,192 tokens, making it well-suited for documents, RAG setups, classification, clustering, and more.",
      "recordSize": "103.64 MB",
      "modelSize": "137M params",
      "supportedLanguages": [ "English" ],
      "tagline": "Open-source embedder for RAG, clustering, and classification.",
      "name": "nomic-embed-text-v1.5",
      "agentGuid": "B549A8F5-02AF-48FB-93E5-F5CA2802C692",
      "hfRepo": "https://huggingface.co/nomic-ai/nomic-embed-text-v1.5"
    },
    {
      "model": "Nomic-embed-text-v1.5",
      "license": "Apache 2.0",
      "type": "Embedding",
      "platform": "ARM64",
      "hardware": "CPU",
      "hardwareVendor": "Qualcomm",
      "zipUrl": "https://dellupdater.dell.com/non_du/ClientService/endpointmgmt/DellAIProStudio/Dell.Model.Nomic-embed-text-v1.5.CPU.ORT.arm64.zip",
      "zipName": "Dell.Model.Nomic-embed-text-v1.5.CPU.ORT.arm64.zip",
      "description": "Nomic‑embed‑text is a high-performing, open-source text embedding model. It supports a maximum context window of 8,192 tokens, making it well-suited for documents, RAG setups, classification, clustering, and more.",
      "recordSize": "101.14 MB",
      "modelSize": "137M params",
      "supportedLanguages": [ "English" ],
      "tagline": "Open-source embedder for RAG, clustering, and classification.",
      "name": "nomic-embed-text-v1.5",
      "agentGuid": "B549A8F5-02AF-48FB-93E5-F5CA2802C692",
      "hfRepo": "https://huggingface.co/nomic-ai/nomic-embed-text-v1.5"
    },
    {
      "model": "Devstral-Small-2507",
      "license": "Apache 2.0",
      "type": "LLM",
      "platform": "X64",
      "hardware": "GPU",
      "hardwareVendor": "Intel",
      "zipUrl": "http://dellupdater.dell.com/non_du/ClientService/endpointmgmt/dpais/model/llamacpp/Dell.Model.Devstral-Small-2507.GPU.LCPP-CUDA.x64.zip",
      "zipName": "Dell.Model.Devstral-Small-2507.GPU.LCPP-CUDA.x64.zip",
      "description": "Devstral is an open-source agentic LLM for software engineering. It excels at using tools to explore codebases, editing multiple files and power software engineering agents.",
      "recordSize": "12.48 GB",
      "modelSize": "23.6B params",
      "supportedLanguages": [ "English", "French", "German", "Spanish", "Portuguese", "Italian", "Japanese", "Korean", "Russian", "Chinese", "Arabic", "Persian", "Indonesian", "Malay", "Nepali", "Polish", "Romanian", "Serbian", "Swedish", "Turkish", "Ukrainian", "Vietnamese", "Hindi", "Bengali" ],
      "tagline": "Devstral is an LLM built for code open-source, powerful, and ready to engineer.",
      "name": "devstral-small-2507",
      "agentGuid": "2A4EAFDD-3741-428A-BA93-B17F7C324DC7",
      "hfRepo": "https://huggingface.co/mistralai/Devstral-Small-2507"
    },
    {
      "model": "Granite-4.0-h-tiny",
      "license": "Apache 2.0",
      "type": "LLM",
      "platform": "X64",
      "hardware": "GPU",
      "hardwareVendor": "Nvidia",
      "zipUrl": "http://dellupdater.dell.com/non_du/ClientService/endpointmgmt/dpais/model/llamacpp/Dell.Model.Granite-4.0-tiny.GPU.LCPP-CUDA.x64.zip",
      "zipName": "Dell.Model.Granite-4.0-tiny.GPU.LCPP-CUDA.x64.zip",
      "description": "Granite Tiny is a 7B parameter MoE instruction-tuned model for multilingual reasoning, summarization, RAG, code, and long-context tasks, optimized for efficient AI assistants and business applications.",
      "recordSize": "4.22 GB",
      "modelSize": "6.67B params",
      "supportedLanguages": [ "English", "German", "Spanish", "French", "Japanese", "Portuguese", "Arabic", "Czech", "Italian", "Korean", "Dutch", "Chinese" ],
      "tagline": "Lightweight Granite model for multilingual, long context reasoning and AI assistants.",
      "name": "granite-4.0-h-tiny",
      "agentGuid": "D2C55738-847C-4F49-BC0D-813A7A6744E8",
      "hfRepo": "https://huggingface.co/ibm-granite/granite-4.0-tiny-preview"
    },
    {
      "model": "Granite-4.0-h-small",
      "license": "Apache 2.0",
      "type": "LLM",
      "platform": "X64",
      "hardware": "GPU",
      "hardwareVendor": "Nvidia",
      "zipUrl": "http://dellupdater.dell.com/non_du/ClientService/endpointmgmt/dpais/model/llamacpp/Dell.Model.Granite-4.0-small.GPU.LCPP-CUDA.x64.zip",
      "zipName": "Dell.Model.Granite-4.0-small.GPU.LCPP-CUDA.x64.zip",
      "description": "Granite Small is a 32B parameter instruction-tuned model designed for enterprise-grade AI assistants. It supports multilingual reasoning, summarization, RAG, code generation, and tool-calling with long-context capabilities.",
      "recordSize": "18.1 GB",
      "modelSize": "32.2B params",
      "supportedLanguages": [ "English", "German", "Spanish", "French", "Japanese", "Portuguese", "Arabic", "Czech", "Italian", "Korean", "Dutch", "Chinese" ],
      "tagline": "Enterprise ready Granite model for powerful, multilingual AI assistants.",
      "name": "granite-4.0-h-small",
      "agentGuid": "2D47BFE0-DF0A-484B-A0C1-64356A27CC23",
      "hfRepo": "https://huggingface.co/ibm-granite/granite-4.0-h-small"
    }
  ]
}