1:"$Sreact.fragment"
3:I[87555,[],""]
4:I[31295,[],""]
6:I[59665,[],"OutletBoundary"]
8:I[74911,[],"AsyncMetadataOutlet"]
a:I[59665,[],"ViewportBoundary"]
c:I[59665,[],"MetadataBoundary"]
d:"$Sreact.suspense"
f:I[28393,[],""]
:HL["/dell-pro-ai-studio/_next/static/css/64dbf5079a248559.css","style"]
:HL["/dell-pro-ai-studio/_next/static/css/59ed3440722801e9.css","style"]
:HL["/dell-pro-ai-studio/_next/static/css/c65696011e54f24a.css","style"]
0:{"P":null,"b":"DEslET7SBXGFDxNT4Xr0Q","p":"/dell-pro-ai-studio","c":["","api-reference"],"i":false,"f":[[["",{"children":[["mdxPath","api-reference","oc"],{"children":["__PAGE__",{}]}]},"$undefined","$undefined",true],["",["$","$1","c",{"children":[[["$","link","0",{"rel":"stylesheet","href":"/dell-pro-ai-studio/_next/static/css/64dbf5079a248559.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}],["$","link","1",{"rel":"stylesheet","href":"/dell-pro-ai-studio/_next/static/css/59ed3440722801e9.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}],["$","link","2",{"rel":"stylesheet","href":"/dell-pro-ai-studio/_next/static/css/c65696011e54f24a.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}]],"$L2"]}],{"children":[["mdxPath","api-reference","oc"],["$","$1","c",{"children":[null,["$","$L3",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L4",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":["__PAGE__",["$","$1","c",{"children":["$L5",null,["$","$L6",null,{"children":["$L7",["$","$L8",null,{"promise":"$@9"}]]}]]}],{},null,false]},null,false]},null,false],["$","$1","h",{"children":[null,[["$","$La",null,{"children":"$Lb"}],null],["$","$Lc",null,{"children":["$","div",null,{"hidden":true,"children":["$","$d",null,{"fallback":null,"children":"$Le"}]}]}]]}],false]],"m":"$undefined","G":["$f",[]],"s":false,"S":true}
10:I[35776,["744","static/chunks/949fd6f9-c71f6829915a58b8.js","545","static/chunks/c16f53c3-06b3ca0ad18d73e5.js","468","static/chunks/468-fe0ed7e7f797abf5.js","554","static/chunks/554-8dc1a5e5725c0cf7.js","217","static/chunks/app/%5B%5B...mdxPath%5D%5D/page-b1ec7df0e9a09c8d.js"],"ThemeConfigProvider"]
11:I[36666,["744","static/chunks/949fd6f9-c71f6829915a58b8.js","545","static/chunks/c16f53c3-06b3ca0ad18d73e5.js","468","static/chunks/468-fe0ed7e7f797abf5.js","554","static/chunks/554-8dc1a5e5725c0cf7.js","217","static/chunks/app/%5B%5B...mdxPath%5D%5D/page-b1ec7df0e9a09c8d.js"],"LastUpdated"]
12:I[59954,["744","static/chunks/949fd6f9-c71f6829915a58b8.js","545","static/chunks/c16f53c3-06b3ca0ad18d73e5.js","468","static/chunks/468-fe0ed7e7f797abf5.js","419","static/chunks/419-3b4da8cb1e494945.js","554","static/chunks/554-8dc1a5e5725c0cf7.js","177","static/chunks/app/layout-7cb8cb81d1bf3c47.js"],"Search"]
13:I[51362,["744","static/chunks/949fd6f9-c71f6829915a58b8.js","545","static/chunks/c16f53c3-06b3ca0ad18d73e5.js","468","static/chunks/468-fe0ed7e7f797abf5.js","419","static/chunks/419-3b4da8cb1e494945.js","554","static/chunks/554-8dc1a5e5725c0cf7.js","177","static/chunks/app/layout-7cb8cb81d1bf3c47.js"],"ThemeProvider"]
14:I[66221,["744","static/chunks/949fd6f9-c71f6829915a58b8.js","545","static/chunks/c16f53c3-06b3ca0ad18d73e5.js","468","static/chunks/468-fe0ed7e7f797abf5.js","554","static/chunks/554-8dc1a5e5725c0cf7.js","217","static/chunks/app/%5B%5B...mdxPath%5D%5D/page-b1ec7df0e9a09c8d.js"],"SkipNavLink"]
15:I[54486,["744","static/chunks/949fd6f9-c71f6829915a58b8.js","545","static/chunks/c16f53c3-06b3ca0ad18d73e5.js","468","static/chunks/468-fe0ed7e7f797abf5.js","419","static/chunks/419-3b4da8cb1e494945.js","554","static/chunks/554-8dc1a5e5725c0cf7.js","177","static/chunks/app/layout-7cb8cb81d1bf3c47.js"],"ClientBanner"]
16:I[3821,["744","static/chunks/949fd6f9-c71f6829915a58b8.js","545","static/chunks/c16f53c3-06b3ca0ad18d73e5.js","468","static/chunks/468-fe0ed7e7f797abf5.js","419","static/chunks/419-3b4da8cb1e494945.js","554","static/chunks/554-8dc1a5e5725c0cf7.js","177","static/chunks/app/layout-7cb8cb81d1bf3c47.js"],"CloseBannerButton"]
17:I[11226,["744","static/chunks/949fd6f9-c71f6829915a58b8.js","545","static/chunks/c16f53c3-06b3ca0ad18d73e5.js","468","static/chunks/468-fe0ed7e7f797abf5.js","554","static/chunks/554-8dc1a5e5725c0cf7.js","217","static/chunks/app/%5B%5B...mdxPath%5D%5D/page-b1ec7df0e9a09c8d.js"],"ConfigProvider"]
2:["$","html",null,{"lang":"en","dir":"ltr","suppressHydrationWarning":true,"children":[["$","head",null,{"children":[[["$","link",null,{"rel":"shortcut icon","href":"favicon.ico"}],["$","link",null,{"rel":"icon","href":"favicon.ico"}],["$","meta",null,{"name":"google-site-verification","content":"NbXzpY7h8fEKd29X_PUAoUsWS8yXobliCRAfW1yejSY"}]],["$","style",null,{"children":":root {\n  --nextra-primary-hue: 212deg;\n  --nextra-primary-saturation: 100%;\n  --nextra-primary-lightness: 45%;\n  --nextra-bg: 250,250,250;\n  --nextra-content-width: 90rem;\n}\n.dark {\n  --nextra-primary-hue: 204deg;\n  --nextra-primary-saturation: 100%;\n  --nextra-primary-lightness: 55%;\n  --nextra-bg: 17,17,17;\n}\n::selection {\n  background: hsla(var(--nextra-primary-hue),var(--nextra-primary-saturation),var(--nextra-primary-lightness),.3);\n}\nhtml {\n  background: rgb(var(--nextra-bg));\n}"}],["$","meta",null,{"name":"theme-color","media":"(prefers-color-scheme: light)","content":"rgb(250,250,250)"}],["$","meta",null,{"name":"theme-color","media":"(prefers-color-scheme: dark)","content":"rgb(17,17,17)"}],"$undefined"]}],["$","body",null,{"children":["$","$L10",null,{"value":{"children":"$undefined","darkMode":true,"docsRepositoryBase":"https://github.com/dell/dvd-ai-pc-rag/tree/main","editLink":null,"feedback":{"content":null,"labels":"feedback"},"i18n":[],"lastUpdated":["$","$L11",null,{"date":null}],"navigation":{"next":true,"prev":true},"search":["$","$L12",null,{}],"sidebar":{"defaultMenuCollapseLevel":2,"defaultOpen":true,"toggleButton":true},"themeSwitch":{"dark":"Dark","light":"Light","system":"System"},"toc":{"backToTop":"Scroll to top","float":true,"title":"On This Page"}},"children":["$","$L13",null,{"attribute":"class","defaultTheme":"system","disableTransitionOnChange":true,"storageKey":"theme","children":[["$","$L14",null,{}],["$","$L15",null,{"className":"nextra-banner x:max-md:sticky x:top-0 x:z-30 x:flex x:items-center x:px-2 x:text-slate-50 x:dark:text-white x:bg-neutral-900 x:dark:bg-[linear-gradient(1deg,#383838,#212121)] x:print:[display:none]","suppressHydrationWarning":true,"children":[["$","div",null,{"className":"x:w-full x:text-center x:font-medium x:text-sm x:py-2.5","children":"v1.1 is out now!"}],["$","$L16",null,{"storageKey":"v1.1","children":[["$","script",null,{"dangerouslySetInnerHTML":{"__html":"try{document.querySelector('.nextra-banner').classList.toggle('x:hidden',localStorage.getItem(\"v1.1\"))}catch(e){}"}}],["$","svg",null,{"viewBox":"0 0 20 20","fill":"currentColor","height":"1em","children":["$","path",null,{"d":"M4.293 4.293a1 1 0 011.414 0L10 8.586l4.293-4.293a1 1 0 111.414 1.414L11.414 10l4.293 4.293a1 1 0 01-1.414 1.414L10 11.414l-4.293 4.293a1 1 0 01-1.414-1.414L8.586 10 4.293 5.707a1 1 0 010-1.414z"}]}]]}]]}],["$","$L17",null,{"pageMap":[{"data":{"getStartedTitle":{"type":"separator","title":"Get Started"},"index":{"type":"doc","title":"Introduction","theme":{"timestamp":false}},"about":{"type":"doc","title":"About","theme":{"timestamp":false}},"quick-start":{"type":"doc","title":"Quick Start","theme":{"timestamp":false}},"model-catalog":{"type":"doc","title":"Model Catalog","theme":{"timestamp":false}},"reference":{"type":"separator","title":"Reference"},"cli":{"type":"doc","title":"Command Line Interface","theme":{"timestamp":false}},"interfacing-sdk":{"type":"doc","title":"Interfacing SDK","theme":{"timestamp":false}},"api-reference":{"type":"doc","title":"API Reference","theme":{"layout":"full","timestamp":false}}}},{"name":"getStartedTitle","type":"separator","title":"Get Started"},{"name":"index","route":"/","frontMatter":{"title":"Dell Pro AI Studio","filePath":"content/index.mdx","timestamp":1759353100000},"title":"Introduction"},{"name":"about","route":"/about","frontMatter":{"title":"Dell Pro AI Studio","filePath":"content/about.mdx","timestamp":1759353100000},"title":"About"},{"name":"quick-start","route":"/quick-start","frontMatter":{"title":"Getting Started with Dell Pro AI Studio","filePath":"content/quick-start.mdx","timestamp":1759353100000},"title":"Quick Start"},{"name":"model-catalog","route":"/model-catalog","frontMatter":{"title":"Available Models","filePath":"content/model-catalog.mdx","timestamp":1759353100000},"title":"Model Catalog"},{"name":"reference","type":"separator","title":"Reference"},{"name":"cli","route":"/cli","frontMatter":{"title":"Dell Pro AI Studio (dpais) CLI","filePath":"content/cli.mdx","timestamp":1759353100000},"title":"Command Line Interface"},{"name":"interfacing-sdk","route":"/interfacing-sdk","frontMatter":{"title":"Integrating SDKs with Local OpenAI-Compatible Services","filePath":"content/interfacing-sdk.mdx","timestamp":1759353100000},"title":"Interfacing SDK"},{"name":"api-reference","route":"/api-reference","frontMatter":{"title":"Dell Pro AI Studio API","filePath":"content/api-reference.mdx","timestamp":1759353100000},"title":"API Reference"}],"navbar":"$L18","footer":"$L19","children":["$L1a","$L1b"]}]]}]}]}]]}]
1c:I[6874,["744","static/chunks/949fd6f9-c71f6829915a58b8.js","545","static/chunks/c16f53c3-06b3ca0ad18d73e5.js","468","static/chunks/468-fe0ed7e7f797abf5.js","554","static/chunks/554-8dc1a5e5725c0cf7.js","217","static/chunks/app/%5B%5B...mdxPath%5D%5D/page-b1ec7df0e9a09c8d.js"],""]
1d:I[33063,["744","static/chunks/949fd6f9-c71f6829915a58b8.js","545","static/chunks/c16f53c3-06b3ca0ad18d73e5.js","468","static/chunks/468-fe0ed7e7f797abf5.js","554","static/chunks/554-8dc1a5e5725c0cf7.js","217","static/chunks/app/%5B%5B...mdxPath%5D%5D/page-b1ec7df0e9a09c8d.js"],"Image"]
1e:I[85396,["744","static/chunks/949fd6f9-c71f6829915a58b8.js","545","static/chunks/c16f53c3-06b3ca0ad18d73e5.js","468","static/chunks/468-fe0ed7e7f797abf5.js","554","static/chunks/554-8dc1a5e5725c0cf7.js","217","static/chunks/app/%5B%5B...mdxPath%5D%5D/page-b1ec7df0e9a09c8d.js"],"ClientNavbar"]
20:I[12040,["744","static/chunks/949fd6f9-c71f6829915a58b8.js","545","static/chunks/c16f53c3-06b3ca0ad18d73e5.js","468","static/chunks/468-fe0ed7e7f797abf5.js","554","static/chunks/554-8dc1a5e5725c0cf7.js","217","static/chunks/app/%5B%5B...mdxPath%5D%5D/page-b1ec7df0e9a09c8d.js"],"Switchers"]
21:I[22001,["744","static/chunks/949fd6f9-c71f6829915a58b8.js","545","static/chunks/c16f53c3-06b3ca0ad18d73e5.js","468","static/chunks/468-fe0ed7e7f797abf5.js","554","static/chunks/554-8dc1a5e5725c0cf7.js","217","static/chunks/app/%5B%5B...mdxPath%5D%5D/page-b1ec7df0e9a09c8d.js"],"LocaleSwitch"]
22:I[15025,["744","static/chunks/949fd6f9-c71f6829915a58b8.js","545","static/chunks/c16f53c3-06b3ca0ad18d73e5.js","468","static/chunks/468-fe0ed7e7f797abf5.js","554","static/chunks/554-8dc1a5e5725c0cf7.js","217","static/chunks/app/%5B%5B...mdxPath%5D%5D/page-b1ec7df0e9a09c8d.js"],"ThemeSwitch"]
23:I[44502,["744","static/chunks/949fd6f9-c71f6829915a58b8.js","545","static/chunks/c16f53c3-06b3ca0ad18d73e5.js","468","static/chunks/468-fe0ed7e7f797abf5.js","554","static/chunks/554-8dc1a5e5725c0cf7.js","217","static/chunks/app/%5B%5B...mdxPath%5D%5D/page-b1ec7df0e9a09c8d.js"],"MobileNav"]
1f:T481,M12 3C7.0275 3 3 7.12937 3 12.2276C3 16.3109 5.57625 19.7597 9.15374 20.9824C9.60374 21.0631 9.77249 20.7863 9.77249 20.5441C9.77249 20.3249 9.76125 19.5982 9.76125 18.8254C7.5 19.2522 6.915 18.2602 6.735 17.7412C6.63375 17.4759 6.19499 16.6569 5.8125 16.4378C5.4975 16.2647 5.0475 15.838 5.80124 15.8264C6.51 15.8149 7.01625 16.4954 7.18499 16.7723C7.99499 18.1679 9.28875 17.7758 9.80625 17.5335C9.885 16.9337 10.1212 16.53 10.38 16.2993C8.3775 16.0687 6.285 15.2728 6.285 11.7432C6.285 10.7397 6.63375 9.9092 7.20749 9.26326C7.1175 9.03257 6.8025 8.08674 7.2975 6.81794C7.2975 6.81794 8.05125 6.57571 9.77249 7.76377C10.4925 7.55615 11.2575 7.45234 12.0225 7.45234C12.7875 7.45234 13.5525 7.55615 14.2725 7.76377C15.9937 6.56418 16.7475 6.81794 16.7475 6.81794C17.2424 8.08674 16.9275 9.03257 16.8375 9.26326C17.4113 9.9092 17.76 10.7281 17.76 11.7432C17.76 15.2843 15.6563 16.0687 13.6537 16.2993C13.98 16.5877 14.2613 17.1414 14.2613 18.0065C14.2613 19.2407 14.25 20.2326 14.25 20.5441C14.25 20.7863 14.4188 21.0746 14.8688 20.9824C16.6554 20.364 18.2079 19.1866 19.3078 17.6162C20.4077 16.0457 20.9995 14.1611 21 12.2276C21 7.12937 16.9725 3 12 3Z18:["$","header",null,{"className":"nextra-navbar x:sticky x:top-0 x:z-30 x:w-full x:bg-transparent x:print:hidden x:max-md:[.nextra-banner:not([class$=hidden])~&]:top-(--nextra-banner-height)","children":[["$","div",null,{"className":"nextra-navbar-blur x:absolute x:-z-1 x:size-full nextra-border x:border-b x:backdrop-blur-md x:bg-nextra-bg/70"}],["$","nav",null,{"style":{"height":"var(--nextra-navbar-height)"},"className":"x:mx-auto x:flex x:max-w-(--nextra-content-width) x:items-center x:gap-4 x:pl-[max(env(safe-area-inset-left),1.5rem)] x:pr-[max(env(safe-area-inset-right),1.5rem)] x:justify-end","children":[["$","$L1c",null,{"href":"/","className":"x:flex x:items-center x:me-auto x:transition-opacity x:focus-visible:nextra-focus x:hover:opacity-75","aria-label":"Home page","children":["$","div",null,{"style":{"display":"flex","alignItems":"center"},"children":[["$","$L1d",null,{"src":{"src":"/dell-pro-ai-studio//_next/static/media/Dell_Technologies_logo.14d36ae9.svg","height":132,"width":1017,"blurWidth":0,"blurHeight":0},"style":{"width":"40%","height":"auto"},"alt":"Logo"}],["$","div",null,{"style":{"height":"1.5em","width":"1px","backgroundColor":"#ccc","margin":"0 12px"}}],["$","span",null,{"style":{"fontWeight":600,"fontSize":"1em"},"children":"Dell Pro AI Studio"}]]}]}],["$","$L1e",null,{"className":"","children":[["$","a",null,{"href":"https://github.com/dell/dell-pro-ai-studio","target":"_blank","rel":"noreferrer","children":[["$","svg",null,{"fill":"currentColor","viewBox":"3 3 18 18","height":"24","aria-label":"Project repository","children":["$","path",null,{"d":"$1f"}]}],false],"className":"x:focus-visible:nextra-focus"}],"$undefined","$undefined"]}]]}]]}]
19:["$","div",null,{"className":"x:bg-gray-100 x:pb-[env(safe-area-inset-bottom)] x:dark:bg-neutral-900 x:print:bg-transparent","children":[["$","$L20",null,{"children":["$","div",null,{"className":"x:mx-auto x:flex x:max-w-(--nextra-content-width) x:gap-2 x:py-2 x:px-4","children":[["$","$L21",null,{}],["$","$L22",null,{}]]}]}],["$","hr",null,{"className":"nextra-border"}],["$","footer",null,{"className":"x:mx-auto x:flex x:max-w-(--nextra-content-width) x:justify-center x:py-12 x:text-gray-600 x:dark:text-gray-400 x:md:justify-start x:pl-[max(env(safe-area-inset-left),1.5rem)] x:pr-[max(env(safe-area-inset-right),1.5rem)]","children":["Dell Pro AI Studio ",2025," Â©"]}]]}]
1a:["$","$L23",null,{}]
1b:["$","$L3",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L4",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":404}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]],[]],"forbidden":"$undefined","unauthorized":"$undefined"}]
24:I[9608,["744","static/chunks/949fd6f9-c71f6829915a58b8.js","545","static/chunks/c16f53c3-06b3ca0ad18d73e5.js","468","static/chunks/468-fe0ed7e7f797abf5.js","554","static/chunks/554-8dc1a5e5725c0cf7.js","217","static/chunks/app/%5B%5B...mdxPath%5D%5D/page-b1ec7df0e9a09c8d.js"],"TOCProvider"]
25:I[44502,["744","static/chunks/949fd6f9-c71f6829915a58b8.js","545","static/chunks/c16f53c3-06b3ca0ad18d73e5.js","468","static/chunks/468-fe0ed7e7f797abf5.js","554","static/chunks/554-8dc1a5e5725c0cf7.js","217","static/chunks/app/%5B%5B...mdxPath%5D%5D/page-b1ec7df0e9a09c8d.js"],"Sidebar"]
26:I[90911,["744","static/chunks/949fd6f9-c71f6829915a58b8.js","545","static/chunks/c16f53c3-06b3ca0ad18d73e5.js","468","static/chunks/468-fe0ed7e7f797abf5.js","554","static/chunks/554-8dc1a5e5725c0cf7.js","217","static/chunks/app/%5B%5B...mdxPath%5D%5D/page-b1ec7df0e9a09c8d.js"],"ClientWrapper"]
27:I[86186,["744","static/chunks/949fd6f9-c71f6829915a58b8.js","545","static/chunks/c16f53c3-06b3ca0ad18d73e5.js","468","static/chunks/468-fe0ed7e7f797abf5.js","554","static/chunks/554-8dc1a5e5725c0cf7.js","217","static/chunks/app/%5B%5B...mdxPath%5D%5D/page-b1ec7df0e9a09c8d.js"],"default"]
28:T15814,openapi: 3.1.0
info:
  title: Dell Pro AI Studio API
  description: The Dell Pro AI Studio OpenAI REST API.
  version: 1.0.0
  termsOfService: https://www.dell.com/en-us/lp/legal/art-software-license-agreements
  contact:
    name: Dell Pro AI Studio OpenAI API Support
    url: https://www.dell.com/support/home/en-us
servers:
- url: http://localhost:8553/v1
paths:
  /openai/models:
    get:
      operationId: listModels
      tags:
        - Models
      summary: Lists the currently available models, and provides basic information
        about each one such as the owner and availability.
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ListModelsResponse"
        "400":
          description: Bad Request
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/errorResponse'
              examples:
                Error Response Example:
                  value:
                    type: 'https://tools.ietf.org/html/rfc7231#section-6.5.1'
                    title: One or more validation errors occurred.
                    status: 400
                    traceId: '|7fb5e16a-4c8f23bbfc974667.'
        "403":
          description: Forbidden
        "500":
          description: Internal Server Error
  /openai/models/{model}:
    get:
      operationId: retrieveModel
      tags:
        - Models
      summary: Retrieves a model instance, providing basic information about the model
        such as the owner and permissioning.(not currently supported)
      description: "Not Implemented"
      parameters:
        - in: path
          name: model
          required: true
          schema:
            type: string
            examples: [whisper-small-en]
          description: The ID of the model to use for this request
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/Model"
        "400":
          description: Bad Request
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/errorResponse'
              examples:
                Error Response Example:
                  value:
                    type: 'https://tools.ietf.org/html/rfc7231#section-6.5.1'
                    title: One or more validation errors occurred.
                    status: 400
                    traceId: '|7fb5e16a-4c8f23bbfc974667.'
        "403":
          description: Forbidden
        "500":
          description: Internal Server Error
  /openai/audio/transcriptions:
    post:
      operationId: createTranscription
      tags:
        - Audio
      summary: Creates an English transcription of an audio input.
      requestBody:
        required: true
        content:
          multipart/form-data:
            schema:
              $ref: "#/components/schemas/CreateTranscriptionRequest"
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                oneOf:
                  - $ref: "#/components/schemas/CreateTranscriptionResponseJson"
        "400":
          description: Bad Request
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/errorResponse'
              examples:
                Error Response Example:
                  value:
                    type: 'https://tools.ietf.org/html/rfc7231#section-6.5.1'
                    title: One or more validation errors occurred.
                    status: 400
                    traceId: '|7fb5e16a-4c8f23bbfc974667.'
        "403":
          description: Forbidden
        "500":
          description: Internal Server Error
  /openai/audio/translations:
    post:
      operationId: createTranslation
      tags:
        - Audio
      summary: Translates audio into English (not currently supported)
      deprecated: true
      requestBody:
        required: true
        content:
          multipart/form-data:
            schema:
              $ref: "#/components/schemas/CreateTranslationRequest"
      responses:
        "501":
          description: Not Implemented. Audio translation is not currently supported for Whisper models.
  /openai/chat/completions:
    post:
      operationId: createChatCompletion
      tags:
        - Chat
      summary: >
        Creates a model response for the given chat conversation.
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/CreateChatCompletionRequest"
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/CreateChatCompletionResponse"
        "400":
          description: Bad Request
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/errorResponse'
              examples:
                Error Response Example:
                  value:
                    type: 'https://tools.ietf.org/html/rfc7231#section-6.5.1'
                    title: One or more validation errors occurred.
                    status: 400
                    traceId: '|7fb5e16a-4c8f23bbfc974667.'
        "403":
          description: Forbidden
        "500":
          description: Internal Server Error
  /openai/embeddings:
      post:
        operationId: createEmbedding
        tags:
          - Embeddings
        summary: Creates an embedding vector representing the input text or image.
        requestBody:
          required: true
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/CreateEmbeddingRequest"
        responses:
          "200":
            description: OK
            content:
              application/json:
                schema:
                  $ref: "#/components/schemas/CreateEmbeddingResponse"
          "400":
            description: Bad Request
            content:
              application/json:
                schema:
                  $ref: '#/components/schemas/errorResponse'
                examples:
                  Error Response Example:
                    value:
                      type: 'https://tools.ietf.org/html/rfc7231#section-6.5.1'
                      title: One or more validation errors occurred.
                      status: 400
                      traceId: '|7fb5e16a-4c8f23bbfc974667.'
          "403":
            description: Forbidden
          "500":
            description: Internal Server Error
  /openai/images/variations:
    post:
      operationId: createImageVariation
      tags:
        - Images
      summary: Creates a variation of a given image.
      requestBody:
        required: true
        content:
          multipart/form-data:
            schema:
              $ref: "#/components/schemas/CreateImageVariationRequest"
      responses:
        "200":
          description: OK
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ImagesResponse"
        "400":
          description: Bad Request
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/errorResponse'
              examples:
                Error Response Example:
                  value:
                    type: 'https://tools.ietf.org/html/rfc7231#section-6.5.1'
                    title: One or more validation errors occurred.
                    status: 400
                    traceId: '|7fb5e16a-4c8f23bbfc974667.'
        "403":
          description: Forbidden
        "500":
          description: Internal Server Error
  /llamastack/inference/chat-completion:
    post:
      parameters:
      - description: JSON-encoded provider data which will be made available to the
          adapter servicing the API
        in: header
        name: X-LlamaStack-ProviderData
        required: false
        schema:
          type: string
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ChatCompletionRequest'
        required: true
      responses:
        '200':
          content:
            text/event-stream:
              schema:
                oneOf:
                - $ref: '#/components/schemas/ChatCompletionResponse'
                - $ref: '#/components/schemas/ChatCompletionResponseStreamChunk'
          description: Chat completion response. **OR** SSE-stream of these events.
        "400":
          description: Bad Request
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/errorResponse'
              examples:
                Error Response Example:
                  value:
                    type: 'https://tools.ietf.org/html/rfc7231#section-6.5.1'
                    title: One or more validation errors occurred.
                    status: 400
                    traceId: '|7fb5e16a-4c8f23bbfc974667.'
        "403":
          description: Forbidden
        "500":
          description: Internal Server Error
      tags:
      - Chat
  /performance:
    post:
      tags:
        - Performance
      summary: >
        Peforms a performance test on specified models.
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/PerformanceRequest'
        required: true
      responses:
        "200":
          description: "Response for Performance test"
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/PerformanceResponse"
        "500":
          description: "Error performing performance test"

components:
  schemas:
    errorResponse:
      title: ErrorResponse
      type: object
      x-examples:
        Error Response Example:
          message: Invalid Model Name
          type: Invalid_Request_Error
          param: request
          code: 533
      properties:
        message:
          type: string
        type:
          type: string
        param:
          type: string
        code:
          type: string
      required:
        - message
        - type
    Model:
      title: Model
      description: Dell Pro AI Studio offering that can be used with the API.
      properties:
        id:
          type: string
          description: The model identifier, which can be referenced in the API endpoints.
        created:
          type: integer
          description: The Unix timestamp (in seconds) when the model was created.
        object:
          type: string
          description: The object type, which is always "model".
          enum:
            - model
        owned_by:
          type: string
          description: The organization that owns the model.
        capability:
          type: string
          description: Capability
      required:
        - id
        - object
        - created
        - owned_by
    ListModelsResponse:
      type: object
      properties:
        object:
          type: string
          enum:
            - list
        data:
          type: array
          items:
            $ref: "#/components/schemas/Model"
      required:
        - object
        - data
    CreateTranscriptionRequest:
      type: object
      additionalProperties: false
      properties:
        file:
          description: >
            The audio file object (not file name) to transcribe, in one of these
            formats: mp3 or wav
          type: string
          format: binary
        model:
          description: >
            ID of the model to use. Only `whisper` (which is powered by an
            open source Whisper V2 model) is currently available.
          examples: [whisper-1]
          anyOf:
            - type: string
            - type: string
              enum:
                - whisper
        language:
          description: >
            The language of the input audio. Supplying the input language in
            [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes)
            format will improve accuracy and latency.
          type: string
        response_format:
          $ref: "#/components/schemas/AudioResponseFormat"
        temperature:
          description: >
            The sampling temperature, between 0 and 1. Higher values like 0.8
            will make the output more random, while lower values like 0.2 will
            make it more focused and deterministic. If set to 0, the model will
            use [log probability](https://en.wikipedia.org/wiki/Log_probability)
            to automatically increase the temperature until certain thresholds
            are hit.
          type: number
          default: 0
      required:
        - file
        - model
    AudioResponseFormat:
      description: >
        The format of the output is `text`.
      type: string
      enum:
        - text
      default: text
    CreateEmbeddingRequest:
      type: object
      additionalProperties: false
      properties:
        input:
          description: >
            Input text to embed, encoded as a string or array of tokens. To
            embed multiple inputs in a single request, pass an array of strings
            or array of token arrays. The input must not exceed the max input
            tokens for the model (8192 tokens for `openai-clip`),
            cannot be an empty string, and any array must be 2048 dimensions or
            less. [Example Python
            code](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken)
            for counting tokens.
          examples: [The quick brown fox jumped over the lazy dog]
          oneOf:
            - type: string
              title: string
              description: The string that will be turned into an embedding.
              default: ""
              examples: [This is a test.]
            - type: array
              title: array
              description: The array of strings that will be turned into an embedding.
              minItems: 1
              maxItems: 2048
              items:
                type: string
                default: ""
              examples: ["This is a test."]
            - type: array
              title: array
              description: The array of integers that will be turned into an embedding.
              minItems: 1
              maxItems: 2048
              items:
                type: integer
              examples: [1212, 318, 257, 1332, 13]
            - type: array
              title: array
              description: The array of arrays containing integers that will be turned into an
                embedding.
              minItems: 1
              maxItems: 2048
              items:
                type: array
                minItems: 1
                items:
                  type: integer
              examples: [1212, 318, 257, 1332, 13]
          x-oaiExpandable: true
        images:
          type: array
          description: >
            Input images to embed, encoded as an array of base64 images. To embed multiple inputs in a single request, pass an array of base64 strings.
          items:
            type: string
          examples:
            - example1: 
                value: "iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAQAAAC1HAwCAAAAC0lEQVR42mNk+A8AAQUBAScY42YAAAAASUVORK5CYII="
        model:
          description: >
            ID of the model to use. You can use the [List
            models] API to see all of your
            available models, or see our [Model overview] for
            descriptions of them.
          examples:
            - example1:
                value: "nomic-embedding-text-v1.5"
          anyOf:
            - type: string
            - type: string
              enum:
                - openai-clip
                - nomic-embedding-text-v1.5
        encoding_format:
          description: The format to return the embeddings in. Currently `float`
          examples:
            - example1:
                value: "float"
          default: float
          type: string
          enum:
            - float
        dimensions:
          description: >
            The number of dimensions the resulting output embeddings should
            have. Only supported in `text-embedding-3` and later models.
          type: integer
          minimum: 1
        user:
          type: string
          examples: ["user-1234"]
          description: >
            A unique identifier representing your end-user, which can help
            Dell Pro AI Studio to monitor and detect abuse.
      required:
        - model
        - input
    CreateEmbeddingResponse:
      type: object
      properties:
        data:
          type: array
          description: The list of embeddings generated by the model.
          items:
            $ref: "#/components/schemas/Embedding"
        model:
          type: string
          description: The name of the model used to generate the embedding.
        object:
          type: string
          description: The object type, which is always "list".
          enum:
            - list
      required:
        - object
        - model
        - data
        - usage
    Embedding:
      type: object
      description: |
        Represents an embedding vector returned by embedding endpoint.
      properties:
        index:
          type: integer
          description: The index of the embedding in the list of embeddings.
        embedding:
          type: array
          description: >
            The embedding vector, which is a list of floats. The length of
            vector depends on the model as listed in the [embedding
            guide].
          items:
            type: number
        object:
          type: string
          description: The object type, which is always "embedding".
          enum:
            - embedding
      required:
        - index
        - object
        - embedding
    CreateImageVariationRequest:
      type: object
      properties:
        image:
          description: The image to use as the basis for the variation(s). Must be a valid
            JPG, WebP, or PNG file, less than 25MB, and square.
          type: string
          format: binary
        model:
          anyOf:
            - type: string
            - type: string
              enum:
                - realesrgan
          default: realesrgan
          examples:
            - example1:
                value: "realesrgan"
          nullable: true
          description: The model to use for image generation. Only `realesrgan` is supported
            at this time.
        response_format:
          type: string
          enum:
            - b64_json
          default: b64_json
          examples:
            - example1:
                value: "b64_json"
          nullable: true
          description: The format in which the generated images are returned. Format will always be returned as b64_json
        user:
          type: string
          examples:
            - example1:
                value: "user-1234"
          description: >
            A unique identifier representing your end-user, which can help
            Dell Pro AI Studio to monitor and detect abuse.
      required:
        - image
    ImagesResponse:
      properties:
        created:
          type: integer
        data:
          type: array
          items:
            $ref: "#/components/schemas/Image"
      required:
        - created
        - data
    Image:
      type: object
      description: Represents the content of an image generated by Dell Pro AI Studio.
      properties:
        b64_json:
          type: string
          description: The base64-encoded JSON of the generated image, if
            `response_format` is `b64_json`.
        revised_prompt:
          type: string
          description: The prompt that was used to generate the image, if there was any
            revision to the prompt.
    EmbeddingsRequest:
      additionalProperties: false
      properties:
        contents:
          items:
            oneOf:
            - type: string
            - $ref: '#/components/schemas/ImageMedia'
            - items:
                oneOf:
                - type: string
                - $ref: '#/components/schemas/ImageMedia'
              type: array
          type: array
        model_id:
          type: string
      required:
      - model_id
      - contents
      type: object
    EmbeddingsResponse:
      additionalProperties: false
      properties:
        embeddings:
          items:
            items:
              type: number
            type: array
          type: array
      required:
      - embeddings
      type: object
    ProviderInfo:
      additionalProperties: false
      properties:
        provider_id:
          type: string
        provider_type:
          type: string
      required:
      - provider_id
      - provider_type
      type: object
    RouteInfo:
      additionalProperties: false
      properties:
        method:
          type: string
        provider_types:
          items:
            type: string
          type: array
        route:
          type: string
      required:
      - route
      - method
      - provider_types
      type: object
    HealthInfo:
      additionalProperties: false
      properties:
        status:
          type: string
      required:
      - status
      type: object
    ChatCompletionRequest:
      additionalProperties: false
      properties:
        logprobs:
          additionalProperties: false
          properties:
            top_k:
              default: 0
              type: integer
          type: object
        messages:
          items:
            oneOf:
            - $ref: '#/components/schemas/UserMessage'
            - $ref: '#/components/schemas/SystemMessage'
            - $ref: '#/components/schemas/CompletionMessage'
          type: array
        model_id:
          type: string
        response_format:
          oneOf:
          - additionalProperties: false
            properties:
              json_schema:
                additionalProperties:
                  oneOf:
                  - type: 'null'
                  - type: boolean
                  - type: number
                  - type: string
                  - type: array
                    items: {}
                  - type: object
                type: object
              type:
                const: json_schema
                default: json_schema
                type: string
            required:
            - type
            - json_schema
            type: object
          - additionalProperties: false
            properties:
              bnf:
                additionalProperties:
                  oneOf:
                  - type: 'null'
                  - type: boolean
                  - type: number
                  - type: string
                  - type: array
                    items: {}
                  - type: object
                type: object
              type:
                const: grammar
                default: grammar
                type: string
            required:
            - type
            - bnf
            type: object
        sampling_params:
          $ref: '#/components/schemas/SamplingParams'
        stream:
          type: boolean
      required:
      - model_id
      - messages
      type: object
    ChatCompletionResponse:
      additionalProperties: false
      properties:
        completion_message:
          $ref: '#/components/schemas/CompletionMessage'
        logprobs:
          items:
            $ref: '#/components/schemas/TokenLogProbs'
          type: array
      required:
      - completion_message
      title: Chat completion response.
      type: object
    ChatCompletionResponseStreamChunk:
      additionalProperties: false
      properties:
        event:
          $ref: '#/components/schemas/ChatCompletionResponseEvent'
      required:
      - event
      title: SSE-stream of these events.
      type: object
    CreateTranscriptionResponseJson:
      type: object
      description: Represents a transcription response returned by model, based on the
        provided input.
      properties:
        text:
          type: string
          description: The transcribed text.
      required:
        - text
    CreateTranscriptionResponseVerboseJson:
      type: object
      description: Represents a verbose json transcription response returned by model,
        based on the provided input.
      properties:
        language:
          type: string
          description: The language of the input audio.
        duration:
          type: string
          description: The duration of the input audio.
        text:
          type: string
          description: The transcribed text.
        words:
          type: array
          description: Extracted words and their corresponding timestamps.
          items:
            $ref: "#/components/schemas/TranscriptionWord"
        segments:
          type: array
          description: Segments of the transcribed text and their corresponding details.
          items:
            $ref: "#/components/schemas/TranscriptionSegment"
      required:
        - language
        - duration
        - text
    CreateTranslationRequest:
      type: object
      additionalProperties: false
      properties:
        file:
          description: >
            The audio file object (not file name) translate, in one of these
            formats: mp3 or wav
          type: string
          format: binary
        model:
          description: >
            ID of the model to use. Only `whisper-1` (which is powered by our
            open source Whisper V2 model) is currently available.
          examples: [whisper-1]
          anyOf:
            - type: string
            - type: string
              enum:
                - whisper-1
        prompt:
          description: >
            An optional text to guide the model's style or continue a previous
            audio segment. The [prompt]
            should be in English.
          type: string
        response_format:
          $ref: "#/components/schemas/AudioResponseFormat"
        temperature:
          description: >
            The sampling temperature, between 0 and 1. Higher values like 0.8
            will make the output more random, while lower values like 0.2 will
            make it more focused and deterministic. If set to 0, the model will
            use [log probability](https://en.wikipedia.org/wiki/Log_probability)
            to automatically increase the temperature until certain thresholds
            are hit.
          type: number
          default: 0
      required:
        - file
        - model
    CreateTranslationResponseJson:
      type: object
      properties:
        text:
          type: string
      required:
        - text
    CreateTranslationResponseVerboseJson:
      type: object
      properties:
        language:
          type: string
          description: The language of the output translation (always `english`).
        duration:
          type: string
          description: The duration of the input audio.
        text:
          type: string
          description: The translated text.
        segments:
          type: array
          description: Segments of the translated text and their corresponding details.
          items:
            $ref: "#/components/schemas/TranscriptionSegment"
      required:
        - language
        - duration
        - text
    CreateChatCompletionRequest:
      type: object
      properties:
        messages:
          description: >
            A list of messages comprising the conversation so far. Depending on
            the [model] you use, different message types (modalities)
            are supported, like [text], [images], and [audio].
          type: array
          minItems: 1
          items:
            $ref: "#/components/schemas/ChatCompletionRequestMessage"
        model:
          description: ID of the model to use. See the [model endpoint
            compatibility] table for
            details on which models work with the Chat API.
          examples: [phi3.5]
          anyOf:
            - type: string
            - type: string
              enum:
                - phi3.5
        frequency_penalty:
          type: number
          default: 0
          minimum: -2
          maximum: 2
          nullable: true
          description: >
            Number between -2.0 and 2.0. Positive values penalize new tokens
            based on their existing frequency in the text so far, decreasing the
            model's likelihood to repeat the same line verbatim.


            [See more information about frequency and presence
            penalties.]
        logit_bias:
          type: object
          default: null
          nullable: true
          additionalProperties:
            type: integer
          description: >
            Modify the likelihood of specified tokens appearing in the
            completion.


            Accepts a JSON object that maps tokens (specified by their token ID
            in the tokenizer) to an associated bias value from -100 to 100.
            Mathematically, the bias is added to the logits generated by the
            model prior to sampling. The exact effect will vary per model, but
            values between -1 and 1 should decrease or increase likelihood of
            selection; values like -100 or 100 should result in a ban or
            exclusive selection of the relevant token.
        logprobs:
          description: Whether to return log probabilities of the output tokens or not. If
            true, returns the log probabilities of each output token returned in
            the `content` of `message`.
          type: boolean
          default: false
          nullable: true
        top_logprobs:
          description: An integer between 0 and 20 specifying the number of most likely
            tokens to return at each token position, each with an associated log
            probability. `logprobs` must be set to `true` if this parameter is
            used.
          type: integer
          minimum: 0
          maximum: 20
          nullable: true
        max_tokens:
          description: >
            The maximum number of [tokens](/tokenizer) that can be generated in
            the chat completion. This value can be used to control
            [costs] for text generated via API.


            This value is now deprecated in favor of `max_completion_tokens`,
            and is not compatible with [o1 series
            models].
          type: integer
          nullable: true
          deprecated: true
        max_completion_tokens:
          description: >
            An upper bound for the number of tokens that can be generated for a
            completion, including visible output tokens and [reasoning
            tokens].
          type: integer
          nullable: true
        presence_penalty:
          type: number
          default: 0
          minimum: -2
          maximum: 2
          nullable: true
          description: >
            Number between -2.0 and 2.0. Positive values penalize new tokens
            based on whether they appear in the text so far, increasing the
            model's likelihood to talk about new topics.


            [See more information about frequency and presence
            penalties.]
        service_tier:
          description: >
            Specifies the latency tier to use for processing the request. This
            parameter is relevant for customers subscribed to the scale tier
            service:
              - If set to 'auto', and the Project is Scale tier enabled, the system will utilize scale tier credits until they are exhausted.
              - If set to 'auto', and the Project is not Scale tier enabled, the request will be processed using the default service tier with a lower uptime SLA and no latency guarentee.
              - If set to 'default', the request will be processed using the default service tier with a lower uptime SLA and no latency guarentee.
              - When not set, the default behavior is 'auto'.

              When this parameter is set, the response body will include the `service_tier` utilized.
          type: string
          enum:
            - auto
            - default
          nullable: true
          default: auto
        stop:
          description: |
            Up to 4 sequences where the API will stop generating further tokens.
          default: null
          oneOf:
            - type: string
              nullable: true
            - type: array
              minItems: 1
              maxItems: 4
              items:
                type: string
        stream:
          description: >
            If set, partial message deltas will be sent. Tokens
            will be sent as data-only [server-sent
            events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format)
            as they become available, with the stream terminated by a `data:
            [DONE]` message. [Example].
          type: boolean
          nullable: true
          default: false
        stream_options:
          $ref: "#/components/schemas/ChatCompletionStreamOptions"
        temperature:
          type: number
          minimum: 0
          maximum: 2
          default: 1
          examples: [1]
          nullable: true
          description: >
            What sampling temperature to use, between 0 and 2. Higher values
            like 0.8 will make the output more random, while lower values like
            0.2 will make it more focused and deterministic.


            We generally recommend altering this or `top_p` but not both.
        top_p:
          type: number
          minimum: 0
          maximum: 1
          default: 1
          examples: [1]
          nullable: true
          description: >
            An alternative to sampling with temperature, called nucleus
            sampling, where the model considers the results of the tokens with
            top_p probability mass. So 0.1 means only the tokens comprising the
            top 10% probability mass are considered.


            We generally recommend altering this or `temperature` but not both.
        tool_choice:
          $ref: "#/components/schemas/ChatCompletionToolChoiceOption"
        parallel_tool_calls:
          $ref: "#/components/schemas/ParallelToolCalls"
        user:
          type: string
          examples: [user-1234]
          description: >
            A unique identifier representing your end-user, which can help
            Dell Pro AI Studio to monitor and detect abuse.
      required:
        - model
        - messages
    CreateChatCompletionResponse:
      type: object
      description: Represents a chat completion response returned by model, based on
        the provided input.
      properties:
        id:
          type: string
          description: A unique identifier for the chat completion.
        choices:
          type: array
          description: A list of chat completion choices. Can be more than one if `n` is
            greater than 1.
          items:
            type: object
            required:
              - finish_reason
              - index
              - message
              - logprobs
            properties:
              finish_reason:
                type: string
                description: >
                  The reason the model stopped generating tokens. This will be
                  `stop` if the model hit a natural stop point or a provided
                  stop sequence,

                  `length` if the maximum number of tokens specified in the
                  request was reached,

                  `content_filter` if content was omitted due to a flag from our
                  content filters,

                  `tool_calls` if the model called a tool, or `function_call`
                  (deprecated) if the model called a function.
                enum:
                  - stop
                  - length
                  - tool_calls
                  - content_filter
                  - function_call
              index:
                type: integer
                description: The index of the choice in the list of choices.
              message:
                $ref: "#/components/schemas/ChatCompletionResponseMessage"
              logprobs:
                description: Log probability information for the choice.
                type: object
                nullable: true
                properties:
                  content:
                    description: A list of message content tokens with log probability information.
                    type: array
                    items:
                      $ref: "#/components/schemas/ChatCompletionTokenLogprob"
                    nullable: true
                  refusal:
                    description: A list of message refusal tokens with log probability information.
                    type: array
                    items:
                      $ref: "#/components/schemas/ChatCompletionTokenLogprob"
                    nullable: true
                required:
                  - content
                  - refusal
        created:
          type: integer
          description: The Unix timestamp (in seconds) of when the chat completion was
            created.
        model:
          type: string
          description: The model used for the chat completion.
        service_tier:
          description: The service tier used for processing the request. This field is
            only included if the `service_tier` parameter is specified in the
            request.
          type: string
          enum:
            - scale
            - default
          examples: [scale]
          nullable: true
        system_fingerprint:
          type: string
          description: >
            This fingerprint represents the backend configuration that the model
            runs with.


            Can be used in conjunction with the `seed` request parameter to
            understand when backend changes have been made that might impact
            determinism.
        object:
          type: string
          description: The object type, which is always `chat.completion`.
          enum:
            - chat.completion
        usage:
          $ref: "#/components/schemas/CompletionUsage"
      required:
        - choices
        - created
        - id
        - model
        - object
    CreateChatCompletionStreamResponse:
      type: object
      description: Represents a streamed chunk of a chat completion response returned
        by model, based on the provided input.
      properties:
        id:
          type: string
          description: A unique identifier for the chat completion. Each chunk has the
            same ID.
        choices:
          type: array
          description: >
            A list of chat completion choices. Can contain more than one
            elements if `n` is greater than 1. Can also be empty for the

            last chunk if you set `stream_options: {"include_usage": true}`.
          items:
            type: object
            required:
              - delta
              - finish_reason
              - index
            properties:
              delta:
                $ref: "#/components/schemas/ChatCompletionStreamResponseDelta"
              logprobs:
                description: Log probability information for the choice.
                type: object
                nullable: true
                properties:
                  content:
                    description: A list of message content tokens with log probability information.
                    type: array
                    items:
                      $ref: "#/components/schemas/ChatCompletionTokenLogprob"
                    nullable: true
                  refusal:
                    description: A list of message refusal tokens with log probability information.
                    type: array
                    items:
                      $ref: "#/components/schemas/ChatCompletionTokenLogprob"
                    nullable: true
                required:
                  - content
                  - refusal
              finish_reason:
                type: string
                description: >
                  The reason the model stopped generating tokens. This will be
                  `stop` if the model hit a natural stop point or a provided
                  stop sequence,

                  `length` if the maximum number of tokens specified in the
                  request was reached,

                  `content_filter` if content was omitted due to a flag from our
                  content filters,

                  `tool_calls` if the model called a tool, or `function_call`
                  (deprecated) if the model called a function.
                enum:
                  - stop
                  - length
                  - tool_calls
                  - content_filter
                  - function_call
                nullable: true
              index:
                type: integer
                description: The index of the choice in the list of choices.
        created:
          type: integer
          description: The Unix timestamp (in seconds) of when the chat completion was
            created. Each chunk has the same timestamp.
        model:
          type: string
          description: The model to generate the completion.
        service_tier:
          description: The service tier used for processing the request. This field is
            only included if the `service_tier` parameter is specified in the
            request.
          type: string
          enum:
            - scale
            - default
          examples: [scale]
          nullable: true
        system_fingerprint:
          type: string
          description: >
            This fingerprint represents the backend configuration that the model
            runs with.

            Can be used in conjunction with the `seed` request parameter to
            understand when backend changes have been made that might impact
            determinism.
        object:
          type: string
          description: The object type, which is always `chat.completion.chunk`.
          enum:
            - chat.completion.chunk
        usage:
          type: object
          nullable: true
          description: >
            An optional field that will only be present when you set
            `stream_options: {"include_usage": true}` in your request.

            When present, it contains a null value except for the last chunk
            which contains the token usage statistics for the entire request.
          properties:
            completion_tokens:
              type: integer
              description: Number of tokens in the generated completion.
            prompt_tokens:
              type: integer
              description: Number of tokens in the prompt.
            total_tokens:
              type: integer
              description: Total number of tokens used in the request (prompt + completion).
          required:
            - prompt_tokens
            - completion_tokens
            - total_tokens
      required:
        - choices
        - created
        - id
        - model
        - object
    ImageMedia:
      additionalProperties: false
      properties:
        image:
          oneOf:
          - additionalProperties: false
            properties:
              format:
                type: string
              format_description:
                type: string
            title: This class represents an image object.  To create
            type: object
          - $ref: '#/components/schemas/URL'
      required:
      - image
      type: object
    URL:
      format: uri
      pattern: ^(https?://|file://|data:)
      type: string
    UserMessage:
      additionalProperties: false
      properties:
        content:
          oneOf:
          - type: string
          - $ref: '#/components/schemas/ImageMedia'
          - items:
              oneOf:
              - type: string
              - $ref: '#/components/schemas/ImageMedia'
            type: array
        context:
          oneOf:
          - type: string
          - $ref: '#/components/schemas/ImageMedia'
          - items:
              oneOf:
              - type: string
              - $ref: '#/components/schemas/ImageMedia'
            type: array
        role:
          const: user
          default: user
          type: string
      required:
      - role
      - content
      type: object
    SystemMessage:
      additionalProperties: false
      properties:
        content:
          oneOf:
          - type: string
          - $ref: '#/components/schemas/ImageMedia'
          - items:
              oneOf:
              - type: string
              - $ref: '#/components/schemas/ImageMedia'
            type: array
        role:
          const: system
          default: system
          type: string
      required:
      - role
      - content
      type: object
    ToolResponseMessage:
      additionalProperties: false
      properties:
        call_id:
          type: string
        content:
          oneOf:
          - type: string
          - $ref: '#/components/schemas/ImageMedia'
          - items:
              oneOf:
              - type: string
              - $ref: '#/components/schemas/ImageMedia'
            type: array
        role:
          const: ipython
          default: ipython
          type: string
        tool_name:
          oneOf:
          - $ref: '#/components/schemas/BuiltinTool'
          - type: string
      required:
      - role
      - call_id
      - tool_name
      - content
      type: object
    CompletionMessage:
      additionalProperties: false
      properties:
        content:
          oneOf:
          - type: string
          - $ref: '#/components/schemas/ImageMedia'
          - items:
              oneOf:
              - type: string
              - $ref: '#/components/schemas/ImageMedia'
            type: array
        role:
          const: assistant
          default: assistant
          type: string
        stop_reason:
          $ref: '#/components/schemas/StopReason'
        tool_calls:
          items:
            $ref: '#/components/schemas/ToolCall'
          type: array
      required:
      - role
      - content
      - stop_reason
      - tool_calls
      type: object
    SamplingParams:
      additionalProperties: false
      properties:
        max_tokens:
          default: 0
          type: integer
        repetition_penalty:
          default: 1.0
          type: number
        strategy:
          $ref: '#/components/schemas/SamplingStrategy'
          default: greedy
        temperature:
          default: 0.0
          type: number
        top_k:
          default: 0
          type: integer
        top_p:
          default: 0.95
          type: number
      required:
      - strategy
      type: object
    ToolChoice:
      enum:
      - auto
      - required
      type: string
    ToolDefinition:
      additionalProperties: false
      properties:
        description:
          type: string
        parameters:
          additionalProperties:
            $ref: '#/components/schemas/ToolParamDefinition'
          type: object
        tool_name:
          oneOf:
          - $ref: '#/components/schemas/BuiltinTool'
          - type: string
      required:
      - tool_name
      type: object
    ToolPromptFormat:
      description: "`json` --\n    Refers to the json format for calling tools.\n\
        \    The json format takes the form like\n    {\n        \"type\": \"function\"\
        ,\n        \"function\" : {\n            \"name\": \"function_name\",\n  \
        \          \"description\": \"function_description\",\n            \"parameters\"\
        : {...}\n        }\n    }\n\n`function_tag` --\n    This is an example of\
        \ how you could define\n    your own user defined format for making tool calls.\n\
        \    The function_tag format looks like this,\n    <function=function_name>(parameters)</function>\n\
        \nThe detailed prompts for each of these formats are added to llama cli"
      enum:
      - json
      - function_tag
      - python_list
      title: This Enum refers to the prompt format for calling custom / zero shot
        tools
      type: string
    TokenLogProbs:
      additionalProperties: false
      properties:
        logprobs_by_token:
          additionalProperties:
            type: number
          type: object
      required:
      - logprobs_by_token
      type: object
    ChatCompletionResponseEvent:
      additionalProperties: false
      properties:
        delta:
          oneOf:
          - type: string
          - $ref: '#/components/schemas/ToolCallDelta'
        event_type:
          $ref: '#/components/schemas/ChatCompletionResponseEventType'
        logprobs:
          items:
            $ref: '#/components/schemas/TokenLogProbs'
          type: array
        stop_reason:
          $ref: '#/components/schemas/StopReason'
      required:
      - event_type
      - delta
      title: Chat completion response event.
      type: object
    TranscriptionWord:
      type: object
      properties:
        word:
          type: string
          description: The text content of the word.
        start:
          type: number
          format: float
          description: Start time of the word in seconds.
        end:
          type: number
          format: float
          description: End time of the word in seconds.
      required:
        - word
        - start
        - end
    TranscriptionSegment:
      type: object
      properties:
        id:
          type: integer
          description: Unique identifier of the segment.
        seek:
          type: integer
          description: Seek offset of the segment.
        start:
          type: number
          format: float
          description: Start time of the segment in seconds.
        end:
          type: number
          format: float
          description: End time of the segment in seconds.
        text:
          type: string
          description: Text content of the segment.
        tokens:
          type: array
          items:
            type: integer
          description: Array of token IDs for the text content.
        temperature:
          type: number
          format: float
          description: Temperature parameter used for generating the segment.
        avg_logprob:
          type: number
          format: float
          description: Average logprob of the segment. If the value is lower than -1,
            consider the logprobs failed.
        compression_ratio:
          type: number
          format: float
          description: Compression ratio of the segment. If the value is greater than 2.4,
            consider the compression failed.
        no_speech_prob:
          type: number
          format: float
          description: Probability of no speech in the segment. If the value is higher
            than 1.0 and the `avg_logprob` is below -1, consider this segment
            silent.
      required:
        - id
        - seek
        - start
        - end
        - text
        - tokens
        - temperature
        - avg_logprob
        - compression_ratio
        - no_speech_prob
    ChatCompletionRequestMessage:
      oneOf:
        - $ref: "#/components/schemas/ChatCompletionRequestSystemMessage"
        - $ref: "#/components/schemas/ChatCompletionRequestUserMessage"
        - $ref: "#/components/schemas/ChatCompletionRequestAssistantMessage"
        - $ref: "#/components/schemas/ChatCompletionRequestToolMessage"
        - $ref: "#/components/schemas/ChatCompletionRequestFunctionMessage"
      x-oaiExpandable: true
    ChatCompletionModalities:
      type: array
      nullable: true
      description: >
        Output types that you would like the model to generate for this request.

        Most models are capable of generating text, which is the default:


        `["text"]`


        The `llama-v3-8b-chat-audio-preview` model can also be used to [generate
        audio]. To

        request that this model generate both text and audio responses, you can

        use:


        `["text", "audio"]`
      items:
        type: string
        enum:
          - text
          - audio
    PredictionContent:
      type: object
      title: Static Content
      description: >
        Static predicted output content, such as the content of a text file that
        is

        being regenerated.
      required:
        - type
        - content
      properties:
        type:
          type: string
          enum:
            - content
          description: |
            The type of the predicted content you want to provide. This type is
            currently always `content`.
        content:
          x-oaiExpandable: true
          description: >
            The content that should be matched when generating a model response.

            If generated tokens would match this content, the entire model
            response

            can be returned much more quickly.
          oneOf:
            - type: string
              title: Text content
              description: |
                The content used for a Predicted Output. This is often the
                text of a file you are regenerating with minor changes.
            - type: array
              description: An array of content parts with a defined type. Supported options
                differ based on the [model] being used to generate
                the response. Can contain text inputs.
              title: Array of content parts
              items:
                $ref: "#/components/schemas/ChatCompletionRequestMessageContentPartText"
              minItems: 1
    ResponseFormatText:
      type: object
      properties:
        type:
          type: string
          description: "The type of response format being defined: `text`"
          enum:
            - text
      required:
        - type
    ResponseFormatJsonObject:
      type: object
      properties:
        type:
          type: string
          description: "The type of response format being defined: `json_object`"
          enum:
            - json_object
      required:
        - type
    ResponseFormatJsonSchema:
      type: object
      properties:
        type:
          type: string
          description: "The type of response format being defined: `json_schema`"
          enum:
            - json_schema
        json_schema:
          type: object
          properties:
            description:
              type: string
              description: A description of what the response format is for, used by the model
                to determine how to respond in the format.
            name:
              type: string
              description: The name of the response format. Must be a-z, A-Z, 0-9, or contain
                underscores and dashes, with a maximum length of 64.
            schema:
              $ref: "#/components/schemas/ResponseFormatJsonSchemaSchema"
            strict:
              type: boolean
              nullable: true
              default: false
              description: Whether to enable strict schema adherence when generating the
                output. If set to true, the model will always follow the exact
                schema defined in the `schema` field. Only a subset of JSON
                Schema is supported when `strict` is `true`. To learn more, read
                the [Structured Outputs guide].
          required:
            - type
            - name
      required:
        - type
        - json_schema
    ChatCompletionStreamOptions:
      description: >
        Options for streaming response. Only set this when you set `stream:
        true`.
      type: object
      nullable: true
      default: null
      properties:
        include_usage:
          type: boolean
          description: >
            If set, an additional chunk will be streamed before the `data:
            [DONE]` message. The `usage` field on this chunk shows the token
            usage statistics for the entire request, and the `choices` field
            will always be an empty array. All other chunks will also include a
            `usage` field, but with a null value.
    ChatCompletionTool:
      type: object
      properties:
        type:
          type: string
          enum:
            - function
          description: The type of the tool. Currently, only `function` is supported.
        function:
          $ref: "#/components/schemas/FunctionObject"
      required:
        - type
        - function
    ChatCompletionToolChoiceOption:
      description: >
        Controls which (if any) tool is called by the model.

        `none` means the model will not call any tool and instead generates a
        message.

        `auto` means the model can pick between generating a message or calling
        one or more tools.

        `required` means the model must call one or more tools.

        Specifying a particular tool via `{"type": "function", "function":
        {"name": "my_function"}}` forces the model to call that tool.


        `none` is the default when no tools are present. `auto` is the default
        if tools are present.
      oneOf:
        - type: string
          description: >
            `none` means the model will not call any tool and instead generates
            a message. `auto` means the model can pick between generating a
            message or calling one or more tools. `required` means the model
            must call one or more tools.
          enum:
            - none
            - auto
            - required
        - $ref: "#/components/schemas/ChatCompletionNamedToolChoice"
      x-oaiExpandable: true
    ParallelToolCalls:
      description: Whether to enable [parallel function
        calling] during tool use.
      type: boolean
      default: true
    ChatCompletionFunctionCallOption:
      type: object
      description: >
        Specifying a particular function via `{"name": "my_function"}` forces
        the model to call that function.
      properties:
        name:
          type: string
          description: The name of the function to call.
      required:
        - name
    ChatCompletionFunctions:
      type: object
      deprecated: true
      properties:
        description:
          type: string
          description: A description of what the function does, used by the model to
            choose when and how to call the function.
        name:
          type: string
          description: The name of the function to be called. Must be a-z, A-Z, 0-9, or
            contain underscores and dashes, with a maximum length of 64.
        parameters:
          $ref: "#/components/schemas/FunctionParameters"
      required:
        - name
    ChatCompletionResponseMessage:
      type: object
      description: A chat completion message generated by the model.
      properties:
        content:
          type: string
          description: The contents of the message.
          nullable: true
        refusal:
          type: string
          description: The refusal message generated by the model.
          nullable: true
        tool_calls:
          $ref: "#/components/schemas/ChatCompletionMessageToolCalls"
        role:
          type: string
          enum:
            - assistant
          description: The role of the author of this message.
        function_call:
          type: object
          deprecated: true
          description: Deprecated and replaced by `tool_calls`. The name and arguments of
            a function that should be called, as generated by the model.
          properties:
            arguments:
              type: string
              description: The arguments to call the function with, as generated by the model
                in JSON format. Note that the model does not always generate
                valid JSON, and may hallucinate parameters not defined by your
                function schema. Validate the arguments in your code before
                calling your function.
            name:
              type: string
              description: The name of the function to call.
          required:
            - name
            - arguments
        audio:
          type: object
          nullable: true
          description: >
            If the audio output modality is requested, this object contains data

            about the audio response from the model.
          x-oaiExpandable: true
          required:
            - id
            - expires_at
            - data
            - transcript
          properties:
            id:
              type: string
              description: Unique identifier for this audio response.
            expires_at:
              type: integer
              description: >
                The Unix timestamp (in seconds) for when this audio response
                will

                no longer be accessible on the server for use in multi-turn

                conversations.
            data:
              type: string
              description: |
                Base64 encoded audio bytes generated by the model, in the format
                specified in the request.
            transcript:
              type: string
              description: Transcript of the audio generated by the model.
      required:
        - role
        - content
        - refusal
    ChatCompletionTokenLogprob:
      type: object
      properties:
        token: &a1
          description: The token.
          type: string
        logprob: &a2
          description: The log probability of this token, if it is within the top 20 most
            likely tokens. Otherwise, the value `-9999.0` is used to signify
            that the token is very unlikely.
          type: number
        bytes: &a3
          description: A list of integers representing the UTF-8 bytes representation of
            the token. Useful in instances where characters are represented by
            multiple tokens and their byte representations must be combined to
            generate the correct text representation. Can be `null` if there is
            no bytes representation for the token.
          type: array
          items:
            type: integer
          nullable: true
        top_logprobs:
          description: List of the most likely tokens and their log probability, at this
            token position. In rare cases, there may be fewer than the number of
            requested `top_logprobs` returned.
          type: array
          items:
            type: object
            properties:
              token:
                description: The token.
                type: string
              logprob:
                description: The log probability of this token, if it is within the top 20 most
                  likely tokens. Otherwise, the value `-9999.0` is used to signify
                  that the token is very unlikely.
                type: number
              bytes:
                description: A list of integers representing the UTF-8 bytes representation of
                  the token. Useful in instances where characters are represented by
                  multiple tokens and their byte representations must be combined to
                  generate the correct text representation. Can be `null` if there is
                  no bytes representation for the token.
                type: array
                items:
                  type: integer
                nullable: true

            required:
              - token
              - logprob
              - bytes
      required:
        - token
        - logprob
        - bytes
        - top_logprobs
    CompletionUsage:
      type: object
      description: Usage statistics for the completion request.
      properties:
        completion_tokens:
          type: integer
          description: Number of tokens in the generated completion.
        prompt_tokens:
          type: integer
          description: Number of tokens in the prompt.
        total_tokens:
          type: integer
          description: Total number of tokens used in the request (prompt + completion).
        completion_tokens_details:
          type: object
          description: Breakdown of tokens used in a completion.
          properties:
            accepted_prediction_tokens:
              type: integer
              description: |
                When using Predicted Outputs, the number of tokens in the
                prediction that appeared in the completion.
            audio_tokens:
              type: integer
              description: Audio input tokens generated by the model.
            reasoning_tokens:
              type: integer
              description: Tokens generated by the model for reasoning.
            rejected_prediction_tokens:
              type: integer
              description: >
                When using Predicted Outputs, the number of tokens in the

                prediction that did not appear in the completion. However, like

                reasoning tokens, these tokens are still counted in the total

                completion tokens for purposes of billing, output, and context
                window

                limits.
        prompt_tokens_details:
          type: object
          description: Breakdown of tokens used in the prompt.
          properties:
            audio_tokens:
              type: integer
              description: Audio input tokens present in the prompt.
            cached_tokens:
              type: integer
              description: Cached tokens present in the prompt.
      required:
        - prompt_tokens
        - completion_tokens
        - total_tokens
    ChatCompletionStreamResponseDelta:
      type: object
      description: A chat completion delta generated by streamed model responses.
      properties:
        content:
          type: string
          description: The contents of the chunk message.
          nullable: true
        function_call:
          deprecated: true
          type: object
          description: Deprecated and replaced by `tool_calls`. The name and arguments of
            a function that should be called, as generated by the model.
          properties:
            arguments:
              type: string
              description: The arguments to call the function with, as generated by the model
                in JSON format. Note that the model does not always generate
                valid JSON, and may hallucinate parameters not defined by your
                function schema. Validate the arguments in your code before
                calling your function.
            name:
              type: string
              description: The name of the function to call.
        tool_calls:
          type: array
          items:
            $ref: "#/components/schemas/ChatCompletionMessageToolCallChunk"
        role:
          type: string
          enum:
            - system
            - user
            - assistant
            - tool
          description: The role of the author of this message.
        refusal:
          type: string
          description: The refusal message generated by the model.
          nullable: true
    BuiltinTool:
      enum:
      - brave_search
      - wolfram_alpha
      - photogen
      - code_interpreter
      type: string
    StopReason:
      enum:
      - end_of_turn
      - end_of_message
      - out_of_tokens
      type: string
    ToolCall:
      additionalProperties: false
      properties:
        arguments:
          additionalProperties:
            oneOf:
            - type: string
            - type: integer
            - type: number
            - type: boolean
            - type: 'null'
            - items:
                oneOf:
                - type: string
                - type: integer
                - type: number
                - type: boolean
                - type: 'null'
              type: array
            - additionalProperties:
                oneOf:
                - type: string
                - type: integer
                - type: number
                - type: boolean
                - type: 'null'
              type: object
          type: object
        call_id:
          type: string
        tool_name:
          oneOf:
          - $ref: '#/components/schemas/BuiltinTool'
          - type: string
      required:
      - call_id
      - tool_name
      - arguments
      type: object
    SamplingStrategy:
      enum:
      - greedy
      - top_p
      - top_k
      type: string
    ToolParamDefinition:
      additionalProperties: false
      properties:
        default:
          oneOf:
          - type: 'null'
          - type: boolean
          - type: number
          - type: string
          - type: array
            items: {}
          - type: object
        description:
          type: string
        param_type:
          type: string
        required:
          default: true
          type: boolean
      required:
      - param_type
      type: object
    ToolCallDelta:
      additionalProperties: false
      properties:
        content:
          oneOf:
          - type: string
          - $ref: '#/components/schemas/ToolCall'
        parse_status:
          $ref: '#/components/schemas/ToolCallParseStatus'
      required:
      - content
      - parse_status
      type: object
    ChatCompletionResponseEventType:
      enum:
      - start
      - complete
      - progress
      type: string
    ChatCompletionRequestSystemMessage:
      type: object
      title: System message
      properties:
        content:
          description: The contents of the system message.
          oneOf:
            - type: string
              description: The contents of the system message.
              title: Text content
            - type: array
              description: An array of content parts with a defined type. For system messages,
                only type `text` is supported.
              title: Array of content parts
              items:
                $ref: "#/components/schemas/ChatCompletionRequestSystemMessageContentPart"
              minItems: 1
        role:
          type: string
          enum:
            - system
          description: The role of the messages author, in this case `system`.
        name:
          type: string
          description: An optional name for the participant. Provides the model
            information to differentiate between participants of the same role.
      required:
        - content
        - role
    ChatCompletionRequestUserMessage:
      type: object
      title: User message
      properties:
        content:
          description: |
            The contents of the user message.
          oneOf:
            - type: string
              description: The text contents of the message.
              title: Text content
            - type: array
              description: An array of content parts with a defined type. Supported options
                differ based on the [model] being used to generate
                the response. Can contain text, image, or audio inputs.
              title: Array of content parts
              items:
                $ref: "#/components/schemas/ChatCompletionRequestUserMessageContentPart"
              minItems: 1
          x-oaiExpandable: true
        role:
          type: string
          enum:
            - user
          description: The role of the messages author, in this case `user`.
        name:
          type: string
          description: An optional name for the participant. Provides the model
            information to differentiate between participants of the same role.
      required:
        - content
        - role
    ChatCompletionRequestAssistantMessage:
      type: object
      title: Assistant message
      properties:
        content:
          x-oaiExpandable: true
          nullable: true
          oneOf:
            - type: string
              description: The contents of the assistant message.
              title: Text content
            - type: array
              description: An array of content parts with a defined type. Can be one or more
                of type `text`, or exactly one of type `refusal`.
              title: Array of content parts
              items:
                $ref: "#/components/schemas/ChatCompletionRequestAssistantMessageContentPart"
              minItems: 1
          description: >
            The contents of the assistant message. Required unless `tool_calls`
            or `function_call` is specified.
        refusal:
          nullable: true
          type: string
          description: The refusal message by the assistant.
        role:
          type: string
          enum:
            - assistant
          description: The role of the messages author, in this case `assistant`.
        name:
          type: string
          description: An optional name for the participant. Provides the model
            information to differentiate between participants of the same role.
        audio:
          type: object
          nullable: true
          x-oaiExpandable: true
          description: |
            Data about a previous audio response from the model.
          required:
            - id
          properties:
            id:
              type: string
              description: |
                Unique identifier for a previous audio response from the model.
        tool_calls:
          $ref: "#/components/schemas/ChatCompletionMessageToolCalls"
        function_call:
          type: object
          deprecated: true
          description: Deprecated and replaced by `tool_calls`. The name and arguments of
            a function that should be called, as generated by the model.
          nullable: true
          properties:
            arguments:
              type: string
              description: The arguments to call the function with, as generated by the model
                in JSON format. Note that the model does not always generate
                valid JSON, and may hallucinate parameters not defined by your
                function schema. Validate the arguments in your code before
                calling your function.
            name:
              type: string
              description: The name of the function to call.
          required:
            - arguments
            - name
      required:
        - role
    ChatCompletionRequestToolMessage:
      type: object
      title: Tool message
      properties:
        role:
          type: string
          enum:
            - tool
          description: The role of the messages author, in this case `tool`.
        content:
          oneOf:
            - type: string
              description: The contents of the tool message.
              title: Text content
            - type: array
              description: An array of content parts with a defined type. For tool messages,
                only type `text` is supported.
              title: Array of content parts
              items:
                $ref: "#/components/schemas/ChatCompletionRequestToolMessageContentPart"
              minItems: 1
          description: The contents of the tool message.
        tool_call_id:
          type: string
          description: Tool call that this message is responding to.
      required:
        - role
        - content
        - tool_call_id
    ChatCompletionRequestFunctionMessage:
      type: object
      title: Function message
      deprecated: true
      properties:
        role:
          type: string
          enum:
            - function
          description: The role of the messages author, in this case `function`.
        content:
          nullable: true
          type: string
          description: The contents of the function message.
        name:
          type: string
          description: The name of the function to call.
      required:
        - role
        - content
        - name
    ChatCompletionRequestMessageContentPartText:
      type: object
      title: Text content part
      description: |
        Learn about [text inputs].
      properties:
        type:
          type: string
          enum:
            - text
          description: The type of the content part.
        text:
          type: string
          description: The text content.
      required:
        - type
        - text
    ResponseFormatJsonSchemaSchema:
      type: object
      description: The schema for the response format, described as a JSON Schema object.
      additionalProperties: true
    FunctionObject:
      type: object
      properties:
        description:
          type: string
          description: A description of what the function does, used by the model to
            choose when and how to call the function.
        name:
          type: string
          description: The name of the function to be called. Must be a-z, A-Z, 0-9, or
            contain underscores and dashes, with a maximum length of 64.
        parameters:
          $ref: "#/components/schemas/FunctionParameters"
        strict:
          type: boolean
          nullable: true
          default: false
          description: Whether to enable strict schema adherence when generating the
            function call. If set to true, the model will follow the exact
            schema defined in the `parameters` field. Only a subset of JSON
            Schema is supported when `strict` is `true`. Learn more about
            Structured Outputs in the [function calling
            guide](docs/guides/function-calling).
      required:
        - name
    ChatCompletionNamedToolChoice:
      type: object
      description: Specifies a tool the model should use. Use to force the model to
        call a specific function.
      properties:
        type:
          type: string
          enum:
            - function
          description: The type of the tool. Currently, only `function` is supported.
        function:
          type: object
          properties:
            name:
              type: string
              description: The name of the function to call.
          required:
            - name
      required:
        - type
        - function
    FunctionParameters:
      type: object
      description: >-
        The parameters the functions accepts, described as a JSON Schema object.
        See the [guide] for examples, and the [JSON Schema
        reference](https://json-schema.org/understanding-json-schema/) for
        documentation about the format. 


        Omitting `parameters` defines a function with an empty parameter list.
      additionalProperties: true
    ChatCompletionMessageToolCalls:
      type: array
      description: The tool calls generated by the model, such as function calls.
      items:
        $ref: "#/components/schemas/ChatCompletionMessageToolCall"
    ChatCompletionMessageToolCallChunk:
      type: object
      properties:
        index:
          type: integer
        id:
          type: string
          description: The ID of the tool call.
        type:
          type: string
          enum:
            - function
          description: The type of the tool. Currently, only `function` is supported.
        function:
          type: object
          properties:
            name:
              type: string
              description: The name of the function to call.
            arguments:
              type: string
              description: The arguments to call the function with, as generated by the model
                in JSON format. Note that the model does not always generate
                valid JSON, and may hallucinate parameters not defined by your
                function schema. Validate the arguments in your code before
                calling your function.
      required:
        - index
    ChatCompletionRequestSystemMessageContentPart:
      oneOf:
        - $ref: "#/components/schemas/ChatCompletionRequestMessageContentPartText"
      x-oaiExpandable: true
    ChatCompletionRequestUserMessageContentPart:
      oneOf:
        - $ref: "#/components/schemas/ChatCompletionRequestMessageContentPartText"
        - $ref: "#/components/schemas/ChatCompletionRequestMessageContentPartImage"
        - $ref: "#/components/schemas/ChatCompletionRequestMessageContentPartAudio"
      x-oaiExpandable: true
    ToolCallParseStatus:
      enum:
      - started
      - in_progress
      - failure
      - success
      type: string
    ChatCompletionRequestAssistantMessageContentPart:
      oneOf:
        - $ref: "#/components/schemas/ChatCompletionRequestMessageContentPartText"
        - $ref: "#/components/schemas/ChatCompletionRequestMessageContentPartRefusal"
      x-oaiExpandable: true
    ChatCompletionRequestToolMessageContentPart:
      oneOf:
        - $ref: "#/components/schemas/ChatCompletionRequestMessageContentPartText"
      x-oaiExpandable: true
    ChatCompletionRequestMessageContentPartImage:
      type: object
      title: Image content part
      description: |
        Learn about [image inputs].
      properties:
        type:
          type: string
          enum:
            - image_url
          description: The type of the content part.
        image_url:
          type: object
          properties:
            url:
              type: string
              description: Either a URL of the image or the base64 encoded image data.
              format: uri
            detail:
              type: string
              description: Specifies the detail level of the image. Learn more in the [Vision
                guide].
              enum:
                - auto
                - low
                - high
              default: auto
          required:
            - url
      required:
        - type
        - image_url
    ChatCompletionRequestMessageContentPartAudio:
      type: object
      title: Audio content part
      description: |
        Learn about [audio inputs].
      properties:
        type:
          type: string
          enum:
            - input_audio
          description: The type of the content part. Always `input_audio`.
        input_audio:
          type: object
          properties:
            data:
              type: string
              description: Base64 encoded audio data.
            format:
              type: string
              enum:
                - wav
                - mp3
              description: >
                The format of the encoded audio data. Currently supports "wav"
                and "mp3".
          required:
            - data
            - format
      required:
        - type
        - input_audio
    ChatCompletionMessageToolCall:
      type: object
      properties:
        id:
          type: string
          description: The ID of the tool call.
        type:
          type: string
          enum:
            - function
          description: The type of the tool. Currently, only `function` is supported.
        function:
          type: object
          description: The function that the model called.
          properties:
            name:
              type: string
              description: The name of the function to call.
            arguments:
              type: string
              description: The arguments to call the function with, as generated by the model
                in JSON format. Note that the model does not always generate
                valid JSON, and may hallucinate parameters not defined by your
                function schema. Validate the arguments in your code before
                calling your function.
          required:
            - name
            - arguments
      required:
        - id
        - type
    ChatCompletionRequestMessageContentPartRefusal:
      type: object
      title: Refusal content part
      properties:
        type:
          type: string
          enum:
            - refusal
          description: The type of the content part.
        refusal:
          type: string
          description: The refusal message generated by the model.
      required:
        - type
        - refusal
    PerformanceRequest:
      type: object
      title: Performance Request object
      properties:
        model:
          type: string
          description: The model name to run a performance test on.
        trials:
          type: integer
          description: The amount of trials to run in the performance test. Defaults to 5.
          nullable: true
      required:
        - model
      examples:
        - 
          model: "whisper"
          trials: 10
    PerformanceResponse:
      type: object
      title: Performance Response object
      properties:
        model:
          type: string
          description: Name of model from performance test
        trials:
          type: integer
          description: Number of trials ran in performance test
        result:
          type: string
          description: The result of the peformance test
        load_time:
          type: number
          description: Time it takes to load the model
        execution_times:
          type: array
          items:
            type: number
          description: List of execution times for each trial
        average_execution_times:
          type: number
          description: The average execution time of all trials
        extra_metrics:
          type: object
          additionalProperties: true
          description: Dynamic metric storage for performance tests. (e.g. For LLMs, TTFT and TPS)
          nullable: true
      required:
        - model
        - trials
        - result
        - load_time
        - execution_times
        - average_execution_times
      examples:
        -
          model: "phi3.5"
          trials: 10
          result: "Chat Completion performance measured."
          load_time: 6.5
          execution_times: [3.15, 3.16, 3.14, 3.13, 3.15, 3.14, 3.16, 3.15, 3.14, 3.13]
          average_execution_times: 3.145
          extra_metrics:
              time_to_first_token: [1.15, 1.16, 1.14, 1.13, 1.15, 1.14, 1.16, 1.15, 1.14, 1.13]
              tokens_per_second: [8.05, 7.98, 8.546, 8.546, 8.596, 8.126, 8.055, 8.564, 8.564, 8.54]

tags:
- description: Turn audio into text or text into audio.
  name: Audio
- description: Given a list of messages comprising a conversation, the model will
    return a response.
  name: Chat
- description: Get a vector representation of a given input that can be easily consumed
    by machine learning models and algorithms.
  name: Embeddings
- description: Given a prompt and/or an input image, the model will generate a new
    image.
  name: Images
- description: List and describe the various models available in the API.
  name: Models
- description: Perform performance tests on some models
  name: Performance
5:["$","div",null,{"className":"x:mx-auto x:flex x:max-w-(--nextra-content-width)","children":["$","$L24",null,{"value":[],"children":[["$","$L25",null,{}],["$","$L26",null,{"metadata":{"title":"Dell Pro AI Studio API","filePath":"content/api-reference.mdx","timestamp":1759353100000},"bottomContent":"$undefined","children":[["$","div",null,{"id":"nextra-skip-nav"}],["$","main",null,{"data-pagefind-body":true,"children":[["$","h1",null,{"id":"$undefined","className":"x:tracking-tight x:text-slate-900 x:dark:text-slate-100 x:font-bold x:mt-2 x:text-4xl","children":["Dell Pro AI Studio API","$undefined"]}],"\n",["$","$L27",null,{"spec":"$28"}]]}]]}]]}]}]
b:[["$","meta","0",{"charSet":"utf-8"}],["$","meta","1",{"name":"viewport","content":"width=device-width, initial-scale=1"}]]
7:null
29:I[38175,[],"IconMark"]
9:{"metadata":[["$","title","0",{"children":"Dell Pro AI Studio API"}],["$","link","1",{"rel":"icon","href":"/dell-pro-ai-studio/favicon.ico","type":"image/x-icon","sizes":"48x48"}],["$","$L29","2",{}]],"error":null,"digest":"$undefined"}
e:"$9:metadata"
